# POMDP approaches to the multi-arm bandit problem

Comparison of exact dynamic programming (value iteration)
to UCB / Thompson sampling on a small variation of the MAB problem.
Rather than receiving reward at each pull,
reward is only recieved at the the terminal state and each action has uniform cost.
